{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
      "C:\\Windows\\Temp\\ipykernel_20040\\1028885929.py:15: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.shared import Cm\n",
    "\n",
    "# 1. Pobieramy stronę z Wikipedii\n",
    "strona = requests.get(\"https://en.wikipedia.org/wiki/Academy_Award_for_Best_Picture\")\n",
    "zupa = BeautifulSoup(strona.text, \"html.parser\")\n",
    "\n",
    "# 2. Zbieramy tabelki ze zwycięzcami\n",
    "tables = zupa.find_all(\"table\")[2:13]\n",
    "\n",
    "# 3. Łączymy wszystkie tabele w jedną\n",
    "dataframes = [pd.read_html(str(t), flavor=\"lxml\")[0] for t in tables]\n",
    "tabela = pd.concat(dataframes)\n",
    "tabela = tabela.dropna(subset=[\"Film\"])\n",
    "\n",
    "# 4. Wyciągamy listę zwycięzców i lata\n",
    "Rok = \"Przykład\"\n",
    "Rok_nagrody, Lista_zwycięzców = [], []\n",
    "for i, row in enumerate(tabela.iloc[:, 0]):\n",
    "    if row != Rok:\n",
    "        Lista_zwycięzców.append(tabela.Film.iloc[i])\n",
    "        Rok_nagrody.append(Rok)\n",
    "        Rok = row\n",
    "\n",
    "Rok_nagrody = Rok_nagrody[1:]\n",
    "Rok_nagrody.append(\"2023\")  # ostatni rok ręcznie\n",
    "\n",
    "Poprawiony_rok_nagrody = []\n",
    "for r in Rok_nagrody:\n",
    "    znak = r.find(\"(\")\n",
    "    if znak != -1:\n",
    "        r = r[:znak]\n",
    "    Poprawiony_rok_nagrody.append(r.strip())\n",
    "\n",
    "# 5. Zbieramy linki bezpośrednio z tabel (dokładne dopasowanie)\n",
    "linki = []\n",
    "for t in tables:\n",
    "    for a in t.find_all(\"a\"):\n",
    "        href = a.get(\"href\", \"\")\n",
    "        if href.startswith(\"/wiki/\") and \"film\" in href:\n",
    "            linki.append(\"https://en.wikipedia.org\" + href)\n",
    "\n",
    "# Usuwamy duplikaty, zostawiając kolejność\n",
    "seen = set()\n",
    "pełne_linki = []\n",
    "for l in linki:\n",
    "    if l not in seen:\n",
    "        pełne_linki.append(l)\n",
    "        seen.add(l)\n",
    "\n",
    "# Dopasowujemy do liczby filmów\n",
    "pełne_linki = pełne_linki[:len(Lista_zwycięzców)]\n",
    "\n",
    "# 6. Budujemy DataFrame\n",
    "Filmy = pd.DataFrame({\n",
    "    \"Tytuł\": Lista_zwycięzców,\n",
    "    \"Rok_wygrania_Oscara\": Poprawiony_rok_nagrody,\n",
    "    \"Link\": pełne_linki\n",
    "})\n",
    "\n",
    "# 7. Pobieramy reżysera\n",
    "reżyserzy = []\n",
    "for url in Filmy.Link:\n",
    "    strona_f = requests.get(url)\n",
    "    zupa_f = BeautifulSoup(strona_f.text, \"html.parser\")\n",
    "    scrapy = zupa_f.find_all(\"td\", attrs={\"class\": \"infobox-data\"})\n",
    "    if scrapy:\n",
    "        reżyserzy.append(scrapy[0].text.strip())\n",
    "    else:\n",
    "        reżyserzy.append(\"Brak danych\")\n",
    "\n",
    "Filmy[\"Reżyser\"] = reżyserzy\n",
    "\n",
    "# 8. Usuwamy kolumnę Link i zachowujemy tylko potrzebne kolumny\n",
    "Filmy = Filmy[[\"Tytuł\", \"Rok_wygrania_Oscara\", \"Reżyser\"]]\n",
    "\n",
    "# 9. Zapis do Worda\n",
    "document = Document()\n",
    "style = document.styles[\"Normal\"]\n",
    "style.font.name = \"Calibri\"\n",
    "\n",
    "for _, row in Filmy.iterrows():\n",
    "    document.add_paragraph(\"Tytuł: \" + row[\"Tytuł\"])\n",
    "    document.add_paragraph(\"Rok wygrania Oskara: \" + row[\"Rok_wygrania_Oscara\"])\n",
    "    document.add_paragraph(\"Reżyser: \" + row[\"Reżyser\"])\n",
    "    document.add_paragraph(\"\")  # odstęp\n",
    "\n",
    "document.save(\"Opis_Filmów.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
